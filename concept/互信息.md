## 点互信息（PMI）
点互信息（PMI）用来衡量两个离散样本点的联合概率与独立概率的差异，可以用来衡量相关性的大小。

$$ pmi(x;y) = \log \frac{p(x,y)}{p(x)p(y)} $$

举个例子，联合分布为：

| x | y | p(x,y) |
| --- | --- | --- |
| 0 | 0 | 0.1 |
|0|1|0.7|
|1|0|0.15|
|1|1|0.05|

边缘分布为：

| |p(x)|p(y)|
|---|---|---|
|0|0.8|0.25|
|1|0.2|0.75|

可以计算得到(log2)：
$pmi(x=0;y=0)=−1$
$pmi(x=0;y=1)=0.222392$
$pmi(x=1;y=0)=1.584963$
$pmi(x=1;y=1)=-1.584963$


## 互信息（MI）
当然，此时X、Y随机变量的互信息$I(X,Y) = 0.2141709$，即：
$$I(X,Y) = E_{x,y}pmi(x,y) = \sum p(x,y) \log \frac{p(x,y)}{p(x)p(y)} = KL\{p(x,y)||p(x)p(y)\}$$
